Epoch: 1:   0%|                                                                                                                                                                                    | 0/209 [00:00<?, ?it/s]/storage/code/3DCLIP/train_clip3d.py:94: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():  # FP16 mixed precision
Epoch: 1:  27%|██████████████████████████████████████████████▋                                                                                                                            | 57/209 [00:25<01:08,  2.21it/s]
Traceback (most recent call last):
  File "/storage/code/3DCLIP/train_clip3d.py", line 156, in <module>
    train()
  File "/storage/code/3DCLIP/train_clip3d.py", line 107, in train
    scaler.step(optimizer)
  File "/home/bmsha/.conda/envs/artichoke/lib/python3.11/site-packages/torch/amp/grad_scaler.py", line 461, in step
    retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bmsha/.conda/envs/artichoke/lib/python3.11/site-packages/torch/amp/grad_scaler.py", line 355, in _maybe_opt_step
    if not sum(v.item() for v in optimizer_state["found_inf_per_device"].values()):
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bmsha/.conda/envs/artichoke/lib/python3.11/site-packages/torch/amp/grad_scaler.py", line 355, in <genexpr>
    if not sum(v.item() for v in optimizer_state["found_inf_per_device"].values()):
               ^^^^^^^^
KeyboardInterrupt
